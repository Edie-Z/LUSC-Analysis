install.packages("shiny")
install.packages("learnr")
library(MASS)
library(factoextra)
library(cluster)
data = USArrests
View(data)
summary(data)
str(data)
sum(is.na(data))
std_data = scale(data)
head(data)
head(std_data)
d = dist(std_data, method = "euclidean")
methods = c("averge", "complete", "single")
names(methods) =c("averge", "complete", "single")
ac = funcyion(x){
sapply(methods,ac)
ac = funcyion(x){
library(tidyverse)
set.seed(123)
Customer_Data= tibble(CustomerID = 1:200,
Gender = sample(c("Male","Female"),200,replace = TRUE),
Age = sample((18:70), 200, replace = TRUE),
AnnualIncome = round(runif(200,min = 20, max = 100),0),
SpendingScore = sample(1:100, 200, replace = TRUE))
library(ggplot2)
ggplot(Customer_Data, aes(x=Age)) +
geom_histogram(binwidth = 2, fill = "green", color = "blue") +
labs(title = "Annual Income vs. Spending Score by Gender", x = "Annual Income (k$)", y = "Spending Score (k$)")
view(Customer_Data)
head(Customer_Data)
tail(Customer_Data)
summary(Customer_Data)
str(Customer_Data)
ggplot(Customer_Data, aes(x=AnnualIncome, y=SpendingScore, color=Ginder)) +
geom_point(alpha=0.9) +
labs(title = "Annual Income vs. Spending Score by Gender", x = "Annual Income (k$)", y = "Spending Score (k$)")
ggplot(Customer_Data, aes(x=AnnualIncome, y=SpendingScore, color=Ginder)) +
geom_point(alpha=0.9) +
theme_minimal() +
labs(title = "Annual Income vs. Spending Score by Gender", x = "Annual Income (k$)", y = "Spending Score (k$)")
ggplot(Customer_Data, aes(x=Age)) +
geom_histogram(binwidth = 2, fill = "green", color = "blue") +
labs(title = "Age Distribution of Customs", x = "Age", y = "Count")
ggplot(Customer_Data, aes(x=AnnualIncome, y=SpendingScore, color=Ginder)) +
geom_point(alpha=0.9) +
theme_minimal() +
labs(title = "Annual Income vs. Spending Score by Gender", x = "Annual Income (k$)", y = "Spending Score (k$)")
Cust.num$Gender = ifelse(Customer_Data$Gender == "Male", 0, 1)
str(Cust.num)
install.packages("cluster")
install.packages("tidyverse")
install.packages("stats")
install.packages("dplyr")
install.packages("ggplot2")
library(datasets)
data("iris")
View(iris)
iris.labels = iris$Species
flower_data = iris[1:4]
flower_data = iris[ ,-5]
head(flower_data)
tail(flower_data)
summary(flower_data)
str(flower_data)
flower_scale = scale(flower_data)
flower_dist = dist(flower_scale)
flower_data = dist(flower_scale, method = "euclidean")
HCA = hclust(flower_dist)
plot(HCA)
rect.hclust(HCA, k = 3, border = 2 : 6)
library(ggplot2)
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, colour = Species)) +
geom_point() +
labs(title = "Sepal Length vs. Sapel Width", x = "Sepal Length", y = "Sepal Width")
datacluster = cutree(HCA, k = 3)
datacluster
flower_data$cluster = as.factor(datacluster)
print(table(flower_data$cluster))
View(Cluster1)
dc = dist(Cluster1)
datacluster = cutree(HCA, k = 3)
datacluster
flower_data$cluster = as.factor(datacluster)
print(table(flower_data$cluster))
View(Cluster1)
dc = dist(Cluster1)
x = hclust(dc, method = "average")
plot(x)
plot(x, hang = -1)
library(cluster)
data("USArrests")
diana_result <- diana(USArrests)
library(readr)
Cluster1 <- read_csv("C:/Users/MSI-NB/Desktop/UE DS/S2/MA/Cluster1.sav")
View(Cluster1)
library(cluster)
data("USArrests")
diana_result <- diana(USArrests)
plot(diana_result)
fviz_nbclust(flower_scale, kmeans, method = "wss")
KMA = kmeans(flower_scale, centers = 3, nstart = 100)
print(KMA)
KMA.cluster <- KMA$cluster
rownames(flower_scale) = paste(iris$Species, 1 : dim(iris)[1], sep = "_")
fviz_cluster(list(data = flower_scale, cluster = KMA.cluster))
library(MASS)
library(factoextra)
library(cluster)
data = USArrests
View(data)
summary(data)
str(data)
sum(is.na(data))
std_data = scale(data)
head(data)
head(std_data)
d = dist(std_data, method = "euclidean")
methods = c("averge", "complete", "single")
names(methods) =c("averge", "complete", "single")
ac = funcyion(x){
sapply(methods,ac)
library(tidyverse)
set.seed(123)
Customer_Data= tibble(CustomerID = 1:200,
Gender = sample(c("Male","Female"),200,replace = TRUE),
Age = sample((18:70), 200, replace = TRUE),
AnnualIncome = round(runif(200,min = 20, max = 100),0),
SpendingScore = sample(1:100, 200, replace = TRUE))
library(ggplot2)
ggplot(Customer_Data, aes(x=Age)) +
geom_histogram(binwidth = 2, fill = "green", color = "blue") +
labs(title = "Age Distribution of Customs", x = "Age", y = "Count")
ggplot(Customer_Data, aes(x=AnnualIncome, y=SpendingScore, color=Ginder)) +
geom_point(alpha=0.9) +
theme_minimal() +
labs(title = "Annual Income vs. Spending Score by Gender", x = "Annual Income (k$)", y = "Spending Score (k$)")
view(Customer_Data)
head(Customer_Data)
tail(Customer_Data)
summary(Customer_Data)
str(Customer_Data)
Cust.num = Customer_Data
Cust.num$Gender = ifelse(Customer_Data$Gender == "Male", 0, 1)
str(Cust.num)
S
Cust_scale = scale(Cust.num)
library(dendextend)
Cust_scale = scale(Cust.num)
Cust_dist = dist(Cust_scale)
HCA_C = hclist(Cust_dist)
library(dendextend)
plot(HCA_C)
# Load necessary libraries
library(rjson)
library(tidyverse)
# Set working directory
setwd("C:/Users/MSI-NB/Jupyter Code/TCGA_R")
# Load JSON metadata
json_data <- jsonlite::fromJSON("metadata.cart.2024-11-08.json")
View(json_data)
# Load necessary libraries
library(rjson)
library(tidyverse)
# Set working directory
setwd("C:/Users/MSI-NB/Jupyter Code/TCGA_R")
# Load JSON metadata
json_data <- jsonlite::fromJSON("metadata.cart.2024-11-08.json")
View(json_data)
sample_ids <- sapply(json_data$associated_entities, function(x) x[, 1])
sample_ids[1:10]
file_sample <- data.frame(sample_id = sample_ids, file_name = json_data$file_name)
View(file_sample)
# List count files
count_files <- list.files('gdc_download_20241108_123324.776410/', pattern = '*.tsv', recursive = TRUE)
count_files[1:10]
count_file_names <- sapply(strsplit(count_files, split = '/'), function(x) x[2])
count_file_names[1:10]
# Initialize main matrix with 60660 rows (based on assumption)
matrix <- data.frame(matrix(nrow = 60660, ncol = 0))
# Function to read and process each file
process_file <- function(file_path, sample_id) {
data <- read.delim(file_path, fill = TRUE, header = FALSE, row.names = 1, skip = 1)
# Ensure it has at least 6 columns
if (ncol(data) < 6) stop("File format error: Less than 6 columns.")
# Extract 6th column, clean it, convert to numeric, handle NAs
tpm_values <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", data[[6]])))
tpm_values[is.na(tpm_values)] <- 0
# Ensure exactly 60660 rows
length_diff <- 60660 - length(tpm_values)
if (length_diff > 0) {
tpm_values <- c(tpm_values, rep(0, length_diff))
} else if (length_diff < 0) {
tpm_values <- tpm_values[1:60660]
}
# Return as named data frame column
return(data.frame(sample_id = sample_id, tpm_values = tpm_values))
}
# Process each file and bind to main matrix
for (i in seq_along(count_files)) {
path <- file.path("gdc_download_20241108_123324.776410", count_files[i])
sample_id <- file_sample$sample_id[file_sample$file_name == count_file_names[i]]
matrix <- cbind(matrix, setNames(process_file(path, sample_id), sample_id))
}
# Extract gene names and types from the first file
initial_data <- read.delim(file.path("gdc_download_20241108_123324.776410", count_files[1]), fill = TRUE, header = FALSE, row.names = 1)
gene_names[1:10]
initial_data
gene_names <- initial_data[-c(1:6), 1]
gene_names[1:10]
gene_types <- initial_data[-c(1:6), 2]
gene_types[1:10]
# Confirm gene_names and gene_types lengths match
stopifnot(length(gene_names) == length(gene_types))
# Combine gene data with main matrix
matrix0 <- data.frame(gene_type = gene_types, gene_name = gene_names, matrix)
# Check matrix0 before aggregation
cat("Before aggregation and filtering:\n")
print(dim(matrix0))
matrix0
# Perform aggregation by gene_name, taking the maximum across columns
if (nrow(matrix0) > 0) {
matrix0 <- aggregate(. ~ gene_name, data = matrix0, FUN = max)
cat("After aggregation:\n")
print(dim(matrix0))
# Filter for protein-coding genes
matrix0 <- subset(matrix0, gene_type == "protein_coding")
cat("After filtering for protein-coding genes:\n")
print(dim(matrix0))
# Check if matrix0 still has rows after filtering
if (nrow(matrix0) > 0) {
# Set row names by gene_name and drop unnecessary columns
rownames(matrix0) <- matrix0$gene_name
matrix0 <- as.data.frame(matrix0[, -c(1, 2), drop = FALSE])
cat("After removing gene_name and gene_type columns:\n")
print(dim(matrix0))
# Construct matrix1 with ID column
matrix1 <- data.frame(ID = rownames(matrix0), matrix0)
cat("Final matrix1 structure:\n")
print(dim(matrix1))
# Replace dots in column names with hyphens and export the final matrix
colnames(matrix1) <- gsub("[.]", "-", colnames(matrix1))
write.table(matrix1, 'TCGA_LUSC_TPM.txt', sep = "\t", quote = FALSE, row.names = FALSE)
} else {
stop("matrix0 is empty after filtering for protein-coding genes.")
}
} else {
stop("matrix0 is empty before aggregation.")
}
# Load necessary libraries
library(rjson)
library(tidyverse)
# Set working directory
setwd("C:/Users/MSI-NB/Jupyter Code/TCGA_R")
# Load JSON metadata
json_data <- jsonlite::fromJSON("metadata.cart.2024-11-08.json")
View(json_data)
sample_ids <- sapply(json_data$associated_entities, function(x) x[, 1])
sample_ids[1:10]
file_sample <- data.frame(sample_id = sample_ids, file_name = json_data$file_name)
View(file_sample)
# List count files
count_files <- list.files('gdc_download_20241108_123324.776410/', pattern = '*.tsv', recursive = TRUE)
count_files[1:10]
count_file_names <- sapply(strsplit(count_files, split = '/'), function(x) x[2])
count_file_names[1:10]
# Initialize main matrix with 60660 rows (based on assumption)
matrix <- data.frame(matrix(nrow = 60660, ncol = 0))
# Function to read and process each file
process_file <- function(file_path, sample_id) {
data <- read.delim(file_path, fill = TRUE, header = FALSE, row.names = 1, skip = 1)
# Ensure it has at least 6 columns
if (ncol(data) < 6) stop("File format error: Less than 6 columns.")
# Extract 6th column, clean it, convert to numeric, handle NAs
tpm_values <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", data[[6]])))
tpm_values[is.na(tpm_values)] <- 0
# Ensure exactly 60660 rows
length_diff <- 60660 - length(tpm_values)
if (length_diff > 0) {
tpm_values <- c(tpm_values, rep(0, length_diff))
} else if (length_diff < 0) {
tpm_values <- tpm_values[1:60660]
}
# Return as named data frame column
return(data.frame(sample_id = sample_id, tpm_values = tpm_values))
}
# Process each file and bind to main matrix
for (i in seq_along(count_files)) {
path <- file.path("gdc_download_20241108_123324.776410", count_files[i])
sample_id <- file_sample$sample_id[file_sample$file_name == count_file_names[i]]
matrix <- cbind(matrix, setNames(process_file(path, sample_id), sample_id))
}
# Load necessary libraries
library(rjson)
library(tidyverse)
# Set working directory
setwd("C:/Users/MSI-NB/Jupyter Code/TCGA_R")
# Load JSON metadata
json_data <- jsonlite::fromJSON("metadata.cart.2024-11-08.json")
View(json_data)
sample_ids <- sapply(json_data$associated_entities, function(x) x[, 1])
sample_ids[1:10]
file_sample <- data.frame(sample_id = sample_ids, file_name = json_data$file_name)
View(file_sample)
# List count files
count_files <- list.files('gdc_download_20241108_123324.776410/', pattern = '*.tsv', recursive = TRUE)
count_files[1:10]
count_file_names <- sapply(strsplit(count_files, split = '/'), function(x) x[2])
count_file_names[1:10]
# Initialize main matrix with 60660 rows (based on assumption)
matrix <- data.frame(matrix(nrow = 60660, ncol = 0))
# Function to read and process each file
process_file <- function(file_path, sample_id) {
data <- read.delim(file_path, fill = TRUE, header = FALSE, row.names = 1, skip = 1)
# Ensure it has at least 6 columns
if (ncol(data) < 6) stop("File format error: Less than 6 columns.")
# Extract 6th column, clean it, convert to numeric, handle NAs
tpm_values <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", data[[6]])))
tpm_values[is.na(tpm_values)] <- 0
# Ensure exactly 60660 rows
length_diff <- 60660 - length(tpm_values)
if (length_diff > 0) {
tpm_values <- c(tpm_values, rep(0, length_diff))
} else if (length_diff < 0) {
tpm_values <- tpm_values[1:60660]
}
# Return as named data frame column
return(data.frame(sample_id = sample_id, tpm_values = tpm_values))
}
# Process each file and bind to main matrix
for (i in seq_along(count_files)) {
path <- file.path("gdc_download_20241108_123324.776410", count_files[i])
sample_id <- file_sample$sample_id[file_sample$file_name == count_file_names[i]]
matrix <- cbind(matrix, setNames(process_file(path, sample_id), sample_id))
}
# Load necessary libraries
library(rjson)
library(tidyverse)
# Set working directory
setwd("C:/Users/MSI-NB/Jupyter Code/TCGA_R")
# Load JSON metadata
json_data <- jsonlite::fromJSON("metadata.cart.2024-11-08.json")
View(json_data)
sample_ids <- sapply(json_data$associated_entities, function(x) x[, 1])
sample_ids[1:10]
file_sample <- data.frame(sample_id = sample_ids, file_name = json_data$file_name)
View(file_sample)
# List count files
count_files <- list.files('gdc_download_20241108_123324.776410/', pattern = '*.tsv', recursive = TRUE)
count_files[1:10]
count_file_names <- sapply(strsplit(count_files, split = '/'), function(x) x[2])
count_file_names[1:10]
# Initialize main matrix with 60660 rows (based on assumption)
matrix <- data.frame(matrix(nrow = 60660, ncol = 0))
# Function to read and process each file
process_file <- function(file_path, sample_id) {
data <- read.delim(file_path, fill = TRUE, header = FALSE, row.names = 1, skip = 1)
# Ensure it has at least 6 columns
if (ncol(data) < 6) stop("File format error: Less than 6 columns.")
# Extract 6th column, clean it, convert to numeric, handle NAs
tpm_values <- suppressWarnings(as.numeric(gsub("[^0-9.]", "", data[[6]])))
tpm_values[is.na(tpm_values)] <- 0
# Ensure exactly 60660 rows
length_diff <- 60660 - length(tpm_values)
if (length_diff > 0) {
tpm_values <- c(tpm_values, rep(0, length_diff))
} else if (length_diff < 0) {
tpm_values <- tpm_values[1:60660]
}
# Return as named data frame column
return(data.frame(sample_id = sample_id, tpm_values = tpm_values))
}
# Process each file and bind to main matrix
for (i in seq_along(count_files)) {
path <- file.path("gdc_download_20241108_123324.776410", count_files[i])
sample_id <- file_sample$sample_id[file_sample$file_name == count_file_names[i]]
matrix <- cbind(matrix, setNames(process_file(path, sample_id), sample_id))
}
# Extract gene names and types from the first file
initial_data <- read.delim(file.path("gdc_download_20241108_123324.776410", count_files[1]), fill = TRUE, header = FALSE, row.names = 1)
gene_names <- initial_data[-c(1:6), 1]
gene_names[1:10]
gene_types <- initial_data[-c(1:6), 2]
gene_types[1:10]
# Confirm gene_names and gene_types lengths match
stopifnot(length(gene_names) == length(gene_types))
# Combine gene data with main matrix
matrix0 <- data.frame(gene_type = gene_types, gene_name = gene_names, matrix)
# Check matrix0 before aggregation
cat("Before aggregation and filtering:\n")
print(dim(matrix0))
# Perform aggregation by gene_name, taking the maximum across columns
if (nrow(matrix0) > 0) {
matrix0 <- aggregate(. ~ gene_name, data = matrix0, FUN = max)
cat("After aggregation:\n")
print(dim(matrix0))
# Filter for protein-coding genes
matrix0 <- subset(matrix0, gene_type == "protein_coding")
cat("After filtering for protein-coding genes:\n")
print(dim(matrix0))
# Check if matrix0 still has rows after filtering
if (nrow(matrix0) > 0) {
# Set row names by gene_name and drop unnecessary columns
rownames(matrix0) <- matrix0$gene_name
matrix0 <- as.data.frame(matrix0[, -c(1, 2), drop = FALSE])
cat("After removing gene_name and gene_type columns:\n")
print(dim(matrix0))
# Construct matrix1 with ID column
matrix1 <- data.frame(ID = rownames(matrix0), matrix0)
cat("Final matrix1 structure:\n")
print(dim(matrix1))
# Replace dots in column names with hyphens and export the final matrix
colnames(matrix1) <- gsub("[.]", "-", colnames(matrix1))
write.table(matrix1, 'TCGA_LUSC_TPM.txt', sep = "\t", quote = FALSE, row.names = FALSE)
} else {
stop("matrix0 is empty after filtering for protein-coding genes.")
}
} else {
stop("matrix0 is empty before aggregation.")
}
